{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting DehazeNet.py\n"
     ]
    }
   ],
   "source": [
    "%%file DehazeNet.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Function\n",
    "\n",
    "class BasicModule(nn.Module):\n",
    "    \"\"\" A class which encapsulates nn.Module and provides interfaces for quick model loading and saving.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def load(self, path):\n",
    "        \"\"\"Load model from specified path.\"\"\"\n",
    "        self.load_state_dict(torch.load(path))\n",
    "    \n",
    "    def save(self, name):\n",
    "        \"\"\"Save a model to checkpoints/\"\"\"\n",
    "        prefix = 'checkpoints/'\n",
    "        if name == None:\n",
    "            name = strftime(\"%m%d_%H:%M:%S.pth\")\n",
    "        name = prefix + name\n",
    "        torch.save(self.state_dict(), name)\n",
    "        return name         \n",
    "\n",
    "class RankingFunc(Function): \n",
    "    # TODO: check whether it's correct or not\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, x, ranking_size): \n",
    "        c, h, w = x.size()\n",
    "        ctx.y_index = torch.arange(0, h*w).resize(h, w).unsqueeze(0).repeat(c, 1, 1)\n",
    "        ctx.ranking_size = ranking_size\n",
    "        \n",
    "        h_num = h // ranking_size\n",
    "        w_num = w // ranking_size\n",
    "        \n",
    "        ipdb.set_trace()\n",
    "        #TODO: what is the dimension of x????\n",
    "        for i in range(h_num):\n",
    "            for j in range(w_num):\n",
    "                temp1 = x[:, :, i * ranking_size : (i + 1) * ranking_size, j * ranking_size : (j + 1) * ranking_size]\n",
    "                temp2 = ctx.y_index[:, :, i * ranking_size : (i + 1) * ranking_size, j * ranking_size : (j + 1) * ranking_size]\n",
    "                value, index = torch.sort(temp1.resize(c, ranking_size ** 2))\n",
    "                temp1 = value.resize(c, ranking_size, ranking_size)\n",
    "                temp2 = temp2.resize(c, ranking_size ** 2)[index].resize(c, ranking_size, ranking_size)\n",
    "        return x\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_y):\n",
    "        c, h, w = grad_y.size()[0], grad_y.size()[1], grad_y.size()[2]\n",
    "        grad_y = grad_y.resize(c, ctx.ranking_size ** 2)\n",
    "        _, index = ctx.y_index.resize(c, ctx.ranking_size ** 2).sort()\n",
    "        for i in range(c):\n",
    "            grad_y[c] = grad_y[c][index[c]]\n",
    "        grad_y = grad_y.resize(c, h, w)\n",
    "        return grad_y, None\n",
    "    \n",
    "def ranking_func(x, ranking_size):      \n",
    "    h_num = x.size()[2] // ranking_size\n",
    "    w_num = x.size()[3] // ranking_size\n",
    "    for i in range(h_num):\n",
    "        for j in range(w_num):\n",
    "            temp = x[:, :, i * ranking_size : (i + 1) * ranking_size, j * ranking_size : (j + 1) * ranking_size]\n",
    "            value = torch.sort(temp.resize(y.size()[0], y.size()[1], ranking_size * ranking_size))[0]\n",
    "            temp = value.resize(y.size()[0], y.size()[1], ranking_size, ranking_size)\n",
    "    return x\n",
    "\n",
    "class DehazeBlock(BasicModule):\n",
    "    def __init__(self, in_channel, out_channel, kernel_size, dilation = 1, conv = True, ranking = False):\n",
    "        \"\"\"\n",
    "        INPUT PARAMETERS\n",
    "        ----------------------------------------------\n",
    "        dilation: atrous rate\n",
    "        : atrous olution path\n",
    "        ranking: ranking path\n",
    "        ranking_size: the size of each ranking region\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channel, out_channel, kernel_size, 1, (kernel_size - 1)// 2 * dilation, dilation, bias = True)\n",
    "        self.bn = nn.BatchNorm2d(out_channel)\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        \n",
    "        self.has_conv = conv\n",
    "        self.has_ranking = ranking\n",
    "        #TODOï¼šshould we change the size?\n",
    "        self.ranking_size = 2 * dilation  \n",
    "\n",
    "           \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn(self.conv(x)))\n",
    "        if self.has_ranking:\n",
    "            y = RankingFunc.Apply(x, self.raning_size)\n",
    "        if self.has_ranking and self.has_conv:\n",
    "            return torch.cat((x, y), dim = 1)\n",
    "        elif self.has_ranking:\n",
    "            return y\n",
    "        elif self.has_conv:\n",
    "            return x\n",
    "            \n",
    "\n",
    "class DehazePyramid(BasicModule):\n",
    "    def __init__(self, in_channel, out_channel, kernel_size, num, conv = True, ranking = False):\n",
    "        \"\"\"\n",
    "        INPUT PARAMETERS\n",
    "        ----------------------------------------------\n",
    "        num: number of DehazeBlock in each pyramid\n",
    "        conv: atrous convolution path\n",
    "        ranking: ranking path\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.db = nn.ModuleList()\n",
    "        for i in range(num):\n",
    "            self.db.append(DehazeBlock(in_channel, out_channel, kernel_size, dilation = 2**i, \n",
    "                                       conv = conv, ranking = ranking))\n",
    "        self.conv = nn.Conv2d(out_channel * num, out_channel, (1, 1), 1, bias = True)\n",
    "        self.bn = nn.BatchNorm2d(out_channel)\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        \n",
    "        self.num = num\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = []\n",
    "        for i in range(self.num):\n",
    "            y.append(self.db[i](x))\n",
    "        y = torch.cat(y, dim = 1)\n",
    "        y = self.relu(self.bn(self.conv(y)))\n",
    "        return y\n",
    "\n",
    "class DehazeNet(BasicModule):\n",
    "    def __init__(self, kernel_size, rate_num, conv = True, ranking = False):\n",
    "        \"\"\"\n",
    "        INPUT PEREMETERS\n",
    "        -------------------------------------------------\n",
    "        rate_num: number of DehazeBlock in each DehazePyramid\n",
    "        conv: atrous convolution path\n",
    "        ranking: ranking path\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential()\n",
    "        if conv and ranking:\n",
    "            self.net.add_module('DP1', DehazePyramid(6, 16, kernel_size, rate_num, conv, ranking))\n",
    "        else:\n",
    "            self.net.add_module('DP1', DehazePyramid(3, 16, kernel_size, rate_num, conv, ranking))\n",
    "        self.net.add_module('DP2', DehazePyramid(16, 32, kernel_size, rate_num, conv, ranking))\n",
    "        self.net.add_module('DP3', DehazePyramid(32, 64, kernel_size, rate_num, conv, ranking))\n",
    "        self.net.add_module('DP4', DehazePyramid(64, 64, kernel_size, rate_num, conv, ranking))\n",
    "        self.net.add_module('DP5', DehazePyramid(64, 3, kernel_size, rate_num, conv, ranking))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
